---
title: 'Assignment 10'
author: "Saloua Daouki"
date: "2023-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part I:

## Introduction:

The goal of this week's assignment is to practice text processing; first, we are going to get an example code from [Chapter 2: Sentiment analysis with tidy data](https://www.tidytextmining.com/sentiment.html). Then, choose another text and apply the same code to analyze the sentiment of it.

## Loading the librairies:

```{r librairies}
library(tidytext)
library(janeaustenr)
library(tidyverse)
library(stringr)
```

## The sentiments datasets:

```{r}
get_sentiments("afinn")
```

```{r}
get_sentiments("bing")
```

```{r}
get_sentiments("nrc")
```

## Sentiment analysis with inner join

### Tidying the text:

In order to perform sentiment analysis, the text must be in tidy format:

```{r tidy the text}
tidy_books <- austen_books() %>%
  group_by(book) %>%  #to create the column book
  mutate(
    linenumber = row_number(), # to detect which line is the word coming from
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>% # to detect which chapter of the book is the word coming from
  ungroup() %>%
  unnest_tokens(word, text) #to convert the text to tidy format
```

### Sentiments Analysis:

```{r}
library(textdata)
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
```

```{r}
jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

### Visualizing the sentiments scores:

```{r}
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

### Comparing the three sentiments dictionaries:

```{r}
pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice
```

```{r}
afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r}
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

```{r}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)
```

```{r}
get_sentiments("bing") %>% 
  count(sentiment)
```

### Most common positive and negative words:

```{r}
bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```

```{r}
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

```{r}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

# Part II:

## Working with different Corpus:

The text I chose to perform on the sentiment analysis is the lyrics of one of Celine Dion's songs; "That's The Way It Is"

### Loading the text to R

First, let's read the text from my github;

```{r}
Text_D <- readLines("https://raw.githubusercontent.com/SalouaDaouki/Data607/main/Celine%20Dion%3A%20That's%20the%20way%20it%20is") # reading the text file form github source
```

### Tidying the text:

Second, in order to perform sentiment analysis, the text should be tidy. To tidy the text, I need to convert it to a dataframe first;

```{r}
text_df <- tibble( text = Text_D) # Converting the test data into a dataframe
```

Then, I need to "tokenizate" the text, meaning breaking the text into individual words to be able to analyse it;

```{r}
text_df1 <- text_df %>%
  unnest_tokens(word, text) %>% # making the text into a single words
  anti_join(stop_words) # removing the un-necessary words for analysis
```

Now, the text is a tibble with 1 column and 338 rows (single words). We can remove the stop words. after removing the stop words, the number of rows decreases to 76.

Now let's count the most repeated words in the lyrics;

```{r count the repeated words}
text_df1 %>%
  count(word, sort=TRUE)
```

### Visualizing the sentiments:

We can plot the tibble above and focus only on the words that are repeated more than twice.

```{r}
text_df1 %>%
  count(word, sort = TRUE) %>%
  filter(n > 2) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)
```

We can see that the word faith is the most repeated in the song, followed by love.

We also can create a new tibble that have separate columns for negative and positive and also the sentiment of each word;

```{r}
text_df1_sentiment <- text_df1 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, index = row_number() %/% 76, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

To visualize the sentiment of each word, we can plot the text_df1_sentiment into geom_col to show how positive or negative the sentiment of each word;

```{r}
library(ggplot2)

ggplot(text_df1_sentiment, aes(index, sentiment, fill = word)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~word, ncol = 2, scales = "free_x")
```

Based on the plots above, faith and love have the thickest bar in the positive side, which means that they are the most positive words mentioned in the lyrics.

### Comparing the three sentiments:

Now, we can compare the three sentiments dictionaries,

```{r}
afinn <- text_df1 %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = row_number() %/% 76) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  text_df1 %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  text_df1 %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = row_number() %/% 76, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

```

Visualization will allow us to compare the three methods easily;

```{r}
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

For Celine Dion's song, all three methods show the same results, (or maybe I did something wrong in the code that I couldn't figure out?). I am sure something is wrong, because the count of the positive and negative in each lexicon (according to [tidy text mining](https://www.tidytextmining.com/sentiment)) is different, so the plots should be different.

### Most common positive and negative words in the lyrics:

```{r}
bing_word_counts1 <- text_df1 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts1
```

```{r}
bing_word_counts1 %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

Based on the plot above, there are more positive words than negative that are mentioned in the song.

```{r}
text_df1 %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 40))
```

### Another sentiment lexicon:

I typed in the below r chunk "get_sentiments" then four sentiments lexicons appeared, so I picked loughran, because that is the only one I haven't used yet. Let's perform additional sentiment analysis:

First let's get the sentiment for loughran:

```{r}
get_sentiments("loughran")
```

The sentiment of each word using the loughran sentiment lexicon:

```{r}
text_df1_sentiment1 <- text_df1 %>%
  inner_join(get_sentiments("loughran")) %>%
  count(word, index = row_number() %/% 76, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

To visualize the sentiment of each word, we can plot the text_df1_sentiment1 into geom_col to show how positive or negative the sentiment of each word;

```{r}
library(ggplot2)

ggplot(text_df1_sentiment1, aes(index, sentiment, fill = word)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~word, ncol = 2, scales = "free_x")
```

Based on the plots above, easy and win have the bars that are above zero, which means that they are the only positive words mentioned in the lyrics using the loughran lexicon.

Let's compare afinn and loughran methods:

```{r}
afinn1 <- text_df1 %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = row_number() %/% 76) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")
loughran1 <- text_df1 %>%
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = row_number() %/% 76) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "loughran")
```

```{r}
bind_rows(afinn1, loughran1) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

Based on the plot and the data affin1 and loughran 1, both methods captured 37 sentiments from the lyrics.

Let's compare all four:

```{r}

  Afinn_and_loughran <- bind_rows(
  text_df1 %>% 
    inner_join(get_sentiments("afinn")) %>%
    mutate(method = "AFINN"),
  text_df1 %>% 
    inner_join(get_sentiments("loughran") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "loughran")) %>%
  count(method, index = row_number() %/% 76, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
  
  
  
bing_and_nrc1 <- bind_rows(
  text_df1 %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  text_df1 %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = row_number() %/% 76, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

```

```{r}
bind_rows(Afinn_and_loughran,
          bing_and_nrc1, afinn1, loughran1) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

The number of sentiments using each method is different, afinn and loughran have 37 sentiments while bing has 15. The nrc has orund 9 only.

## Conclusion:

Each method gives different results and that is because the number of negative and positive words in each sentiment lexicon is different and also the type of the words are different. For example, in bing, the words that were detected 10 words in the lyrics while only 4 of them were included in loughran plus the word question, which was not common using bing. The most common words using bing were faith and love, but using loughran, the words were easy and win.

## Resources:

-   Tidy Text Mining: Chapter 1: [The tidy Text format](https://www.tidytextmining.com/sentiment) (for tidying the text in part II)

-   Tidy Text Mining: Chapter 2: [Sentiment analysis with tidy data](https://www.tidytextmining.com/sentiment#sentiment)
